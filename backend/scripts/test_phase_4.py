"""
Test script for Phase 4: Conversational Interface (Humanoid)

Tests:
1. IntentClassifier - multilingual intent detection
2. QueryClarifier - "Think Before Plan" analysis
3. ConversationContext - state management
4. DialogueManager - full conversation flow with clarification

Usage:
    python scripts/test_phase_4.py
"""

import asyncio
import logging
import sys
from pathlib import Path
from dotenv import load_dotenv

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.adapters.llm import LLMClientInterface
from src.conversation.context import (
    ConversationContext,
    DialogueState,
    Message,
    MessageRole
)
from src.conversation.intent import IntentClassifier, UserIntent
from src.conversation.clarifier import QueryClarifier, QueryComplexity
from src.conversation.dialogue import DialogueManager
from src.memory import MemoryManager, MemoryContext, SessionOutcome

load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class MockLLMClient(LLMClientInterface):
    """Mock LLM for testing."""

    async def generate(self, prompt: str, json_mode: bool = False, **kwargs) -> str:
        prompt_lower = prompt.lower()

        # Plan generation
        if "research plan" in prompt_lower or "available_tools" in prompt_lower:
            return '''{
                "topic": "Test Topic",
                "summary": "Test research plan",
                "steps": [
                    {
                        "id": 1,
                        "action": "research",
                        "title": "Search arXiv",
                        "description": "Find papers",
                        "queries": ["test query"],
                        "sources": ["arxiv"],
                        "tool": "arxiv_search",
                        "tool_args": {"query": "test", "max_results": 5}
                    }
                ]
            }'''

        # Query clarification (matches "analyze this query" or "research assistant")
        if "analyze" in prompt_lower and "query" in prompt_lower:
            return """UNDERSTANDING: User wants to find attention-free methods and evaluate adaptation to linear transformers
SUBQUERIES: attention-free architectures | linear transformer adaptation
QUESTIONS: Are you looking for existing research or exploring new ideas? | What's your use case - NLP or vision?"""

        return "Mock response"


def test_intent_classifier():
    """Test IntentClassifier with multilingual inputs."""
    logger.info("=" * 60)
    logger.info("Testing IntentClassifier")
    logger.info("=" * 60)

    classifier = IntentClassifier()

    test_cases = [
        ("yes", UserIntent.CONFIRM),
        ("ok", UserIntent.CONFIRM),
        ("ƒë·ªìng √Ω", UserIntent.CONFIRM),
        ("no", UserIntent.CANCEL),
        ("h·ªßy", UserIntent.CANCEL),
        ("add BERT", UserIntent.EDIT),
        ("th√™m transformer", UserIntent.EDIT),
        ("transformer models", UserIntent.NEW_TOPIC),
        ("hi", UserIntent.OTHER),
    ]

    passed = 0
    for message, expected in test_cases:
        result = classifier.classify(message)
        if result.intent == expected:
            passed += 1
            logger.info(f"‚úÖ '{message}' ‚Üí {result.intent.value}")
        else:
            logger.info(f"‚ùå '{message}' ‚Üí {result.intent.value} (expected: {expected.value})")

    logger.info(f"\nResults: {passed}/{len(test_cases)} passed")
    return passed >= len(test_cases) - 1


async def test_query_clarifier():
    """Test QueryClarifier - the 'Think Before Plan' component."""
    logger.info("\n" + "=" * 60)
    logger.info("Testing QueryClarifier (Think Before Plan)")
    logger.info("=" * 60)

    llm = MockLLMClient()
    clarifier = QueryClarifier(llm)

    # Simple query - should NOT need clarification
    simple = await clarifier.analyze("BERT paper")
    logger.info(f"\nQuery: 'BERT paper'")
    logger.info(f"  Needs clarification: {simple.needs_clarification}")
    logger.info(f"  Complexity: {simple.complexity.value}")
    assert not simple.needs_clarification, "Simple query should not need clarification"
    logger.info("‚úÖ Simple query handled correctly")

    # Compound query - SHOULD need clarification
    compound = await clarifier.analyze("find attention-free methods and adapt to linear transformers")
    logger.info(f"\nQuery: 'find attention-free methods and adapt to linear transformers'")
    logger.info(f"  Needs clarification: {compound.needs_clarification}")
    logger.info(f"  Complexity: {compound.complexity.value}")
    logger.info(f"  Understanding: {compound.understanding}")
    logger.info(f"  Sub-queries: {compound.sub_queries}")
    logger.info(f"  Questions: {compound.questions}")
    assert compound.needs_clarification, "Compound query should need clarification"
    assert compound.complexity == QueryComplexity.COMPOUND
    logger.info("‚úÖ Compound query detected correctly")

    # Test message formatting
    message = clarifier.format_clarification_message(compound)
    logger.info(f"\nFormatted message:\n{message}")
    assert "understanding" in message.lower()
    logger.info("‚úÖ Message formatting works")

    return True


def test_conversation_context():
    """Test ConversationContext with new CLARIFYING state."""
    logger.info("\n" + "=" * 60)
    logger.info("Testing ConversationContext")
    logger.info("=" * 60)

    ctx = ConversationContext(conversation_id="test-123")

    assert ctx.state == DialogueState.IDLE
    logger.info("‚úÖ Initial state is IDLE")

    # Test CLARIFYING state
    ctx.transition_to(DialogueState.CLARIFYING)
    assert ctx.state == DialogueState.CLARIFYING
    logger.info("‚úÖ CLARIFYING state works")

    # Test pending_clarification field
    ctx.pending_clarification = {"questions": ["test?"]}
    assert ctx.pending_clarification is not None
    logger.info("‚úÖ pending_clarification field works")

    return True


async def test_dialogue_manager_simple():
    """Test DialogueManager with simple query (no clarification)."""
    logger.info("\n" + "=" * 60)
    logger.info("Testing DialogueManager - Simple Query")
    logger.info("=" * 60)

    llm = MockLLMClient()
    manager = DialogueManager(llm)

    context = await manager.start_conversation()
    logger.info(f"Started conversation {context.conversation_id}")

    # Simple query - should go directly to REVIEWING
    response = await manager.process_message(context.conversation_id, "BERT paper")
    logger.info(f"Response state: {response.state.value}")
    logger.info(f"Message: {response.message[:100]}...")

    # Simple query might still trigger clarification if LLM is used
    # For now, just check we got a valid response
    assert response.state in [DialogueState.REVIEWING, DialogueState.CLARIFYING]
    logger.info("‚úÖ Simple query handled")

    return True


async def test_dialogue_manager_complex():
    """Test DialogueManager with complex query (needs clarification)."""
    logger.info("\n" + "=" * 60)
    logger.info("Testing DialogueManager - Complex Query (Humanoid Flow)")
    logger.info("=" * 60)

    llm = MockLLMClient()
    manager = DialogueManager(llm)

    context = await manager.start_conversation()

    # Complex query - should trigger CLARIFYING
    query = "find attention-free methods and see if they can adapt to linear transformers"
    logger.info(f"\nüë§ User: {query}")

    response = await manager.process_message(context.conversation_id, query)
    logger.info(f"ü§ñ Agent: {response.message[:200]}...")
    logger.info(f"   State: {response.state.value}")

    if response.state == DialogueState.CLARIFYING:
        logger.info("‚úÖ Complex query triggered CLARIFYING state")

        # User provides clarification
        clarification = "I'm looking for existing papers, for NLP tasks"
        logger.info(f"\nüë§ User: {clarification}")

        response = await manager.process_message(context.conversation_id, clarification)
        logger.info(f"ü§ñ Agent: {response.message[:200]}...")
        logger.info(f"   State: {response.state.value}")

        assert response.state == DialogueState.REVIEWING
        logger.info("‚úÖ After clarification, moved to REVIEWING")
    else:
        logger.info("(Query went directly to REVIEWING - LLM-dependent)")

    return True


async def test_dialogue_manager_skip_clarification():
    """Test skipping clarification with 'ok'."""
    logger.info("\n" + "=" * 60)
    logger.info("Testing DialogueManager - Skip Clarification")
    logger.info("=" * 60)

    llm = MockLLMClient()
    manager = DialogueManager(llm)

    context = await manager.start_conversation()

    # Complex query
    query = "compare BERT and GPT and see which is better for summarization"
    logger.info(f"\nüë§ User: {query}")

    response = await manager.process_message(context.conversation_id, query)
    logger.info(f"ü§ñ Agent: {response.message[:150]}...")
    logger.info(f"   State: {response.state.value}")

    if response.state == DialogueState.CLARIFYING:
        # User says "ok" to skip clarification
        logger.info(f"\nüë§ User: ok")
        response = await manager.process_message(context.conversation_id, "ok")
        logger.info(f"ü§ñ Agent: {response.message[:150]}...")
        logger.info(f"   State: {response.state.value}")

        assert response.state == DialogueState.REVIEWING
        logger.info("‚úÖ 'ok' skipped clarification and went to REVIEWING")

    return True


async def test_memory_module():
    """Test Memory module - episodic and procedural memory."""
    logger.info("\n" + "=" * 60)
    logger.info("Testing Memory Module")
    logger.info("=" * 60)

    memory = MemoryManager()

    # Test 1: Get context for new user
    logger.info("\n1. Testing MemoryContext for new user...")
    context = await memory.get_context("new_user", "transformer models")
    assert context.user_experience_level == "new"
    assert not context.has_relevant_history
    logger.info(f"   Experience level: {context.user_experience_level}")
    logger.info("‚úÖ New user context works")

    # Test 2: Record a session
    logger.info("\n2. Testing session recording...")
    await memory.record_session(
        user_id="test_user",
        session_id="session_001",
        topic="attention mechanisms",
        original_query="attention in transformers",
        papers_found=20,
        relevant_papers=8,
        high_relevance_papers=3,
        sources_used=["arxiv"],
        outcome=SessionOutcome.SUCCESS,
        duration_seconds=30.0
    )
    logger.info("   Session recorded (in-memory, Redis not connected)")
    logger.info("‚úÖ Session recording works")

    # Test 3: Learn from interaction
    logger.info("\n3. Testing preference learning...")
    await memory.learn_from_interaction(
        user_id="test_user",
        topic="attention mechanisms",
        language="en",
        sources=["arxiv", "semantic_scholar"]
    )
    prefs = await memory.get_preferences("test_user")
    assert prefs.interaction_count == 1
    logger.info(f"   Interaction count: {prefs.interaction_count}")
    logger.info(f"   Common topics: {prefs.common_topics}")
    logger.info("‚úÖ Preference learning works")

    # Test 4: Test should_skip_clarification
    logger.info("\n4. Testing skip clarification logic...")
    should_skip = await memory.should_skip_clarification("new_user", "test")
    assert not should_skip  # New user should not skip
    logger.info(f"   Should skip (new user): {should_skip}")
    logger.info("‚úÖ Skip clarification logic works")

    # Test 5: MemoryContext formatting
    logger.info("\n5. Testing MemoryContext formatting...")
    context = MemoryContext()
    context.similar_sessions = ["Session 1", "Session 2"]
    context.keywords_effective = ["attention", "transformer"]
    context.has_relevant_history = True
    formatted = context.to_prompt_context()
    assert "Past relevant research" in formatted
    logger.info(f"   Formatted context preview: {formatted[:100]}...")
    logger.info("‚úÖ MemoryContext formatting works")

    return True


async def test_dialogue_with_memory():
    """Test DialogueManager integration with Memory."""
    logger.info("\n" + "=" * 60)
    logger.info("Testing DialogueManager with Memory Integration")
    logger.info("=" * 60)

    llm = MockLLMClient()
    memory = MemoryManager()
    manager = DialogueManager(llm, memory=memory)

    # Start conversation with user_id
    context = await manager.start_conversation(user_id="research_user")
    logger.info(f"Started conversation for user: {context.user_id}")
    assert context.user_id == "research_user"
    logger.info("‚úÖ User ID tracked in conversation")

    # Process a message
    response = await manager.process_message(context.conversation_id, "BERT paper")
    logger.info(f"Response state: {response.state.value}")

    # Verify memory was consulted
    mem_context = await memory.get_context("research_user", "BERT paper")
    logger.info(f"Memory experience level: {mem_context.user_experience_level}")
    logger.info("‚úÖ Memory consulted during processing")

    return True


async def main():
    """Run all Phase 4 tests."""
    logger.info("=" * 80)
    logger.info("Phase 4: Conversational Interface (Humanoid) - Test Suite")
    logger.info("=" * 80)

    results = []

    # Sync tests
    results.append(("IntentClassifier", test_intent_classifier()))
    results.append(("ConversationContext", test_conversation_context()))

    # Async tests
    results.append(("QueryClarifier", await test_query_clarifier()))
    results.append(("DialogueManager (Simple)", await test_dialogue_manager_simple()))
    results.append(("DialogueManager (Complex)", await test_dialogue_manager_complex()))
    results.append(("DialogueManager (Skip)", await test_dialogue_manager_skip_clarification()))
    results.append(("Memory Module", await test_memory_module()))
    results.append(("DialogueManager + Memory", await test_dialogue_with_memory()))

    # Summary
    logger.info("\n" + "=" * 80)
    logger.info("TEST SUMMARY")
    logger.info("=" * 80)

    all_passed = True
    for name, passed in results:
        status = "‚úÖ PASS" if passed else "‚ùå FAIL"
        logger.info(f"{status}: {name}")
        if not passed:
            all_passed = False

    logger.info("=" * 80)
    if all_passed:
        logger.info("‚úÖ ALL TESTS PASSED!")
        logger.info("")
        logger.info("New Flow: IDLE ‚Üí CLARIFYING ‚Üí PLANNING ‚Üí REVIEWING ‚Üí EXECUTING ‚Üí COMPLETE")
        logger.info("The agent now asks clarifying questions like a real researcher!")
        logger.info("Memory: Episodic + Procedural memory integrated for personalization!")
    else:
        logger.info("‚ùå SOME TESTS FAILED")
    logger.info("=" * 80)

    return all_passed


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
